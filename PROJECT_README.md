# ğŸ“š AI Handbook Generator

> **LunarTech AI Engineering Assignment**  
> A chat application that generates comprehensive 20,000-word handbooks from PDF documents using RAG and LongWriter techniques.

---

## ğŸ¯ Project Overview

This application allows users to:
- ğŸ“„ **Upload PDF documents** (research papers, documentation, textbooks)
- ğŸ’¬ **Chat and ask questions** about the uploaded content using RAG
- ğŸ“– **Generate comprehensive handbooks** (20,000+ words) through conversational requests

### Key Features

âœ… **PDF Processing** - Extracts and chunks text from PDFs  
âœ… **Knowledge Graph** - Uses LightRAG for semantic retrieval  
âœ… **Contextual Q&A** - RAG-powered question answering  
âœ… **Long-form Generation** - LongWriter technique for 20k+ word documents  
âœ… **Chat Interface** - Simple, intuitive Gradio UI  
âœ… **Structured Output** - Handbooks with TOC, sections, and proper formatting

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Handbook Generator                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  User Input â†’ PDF Upload â†’ Text Extraction â†’ Chunking      â”‚
â”‚                    â†“                                        â”‚
â”‚            LightRAG Knowledge Graph                         â”‚
â”‚                    â†“                                        â”‚
â”‚      User Query â†’ Context Retrieval â†’ Grok API             â”‚
â”‚                    â†“                                        â”‚
â”‚              Q&A Response / Handbook                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Gradio | Chat interface and PDF upload |
| **LLM** | Grok 4.1 (xAI) | Response generation |
| **RAG** | LightRAG | Knowledge graph and retrieval |
| **PDF Processing** | PyPDF2, pdfplumber | Text extraction |
| **Backend** | Python 3.9+ | Application logic |
| **Storage** | Local cache | Document and embedding storage |

---

## ğŸ“ Project Structure

```
SilverAI-Assignment-AI-Engineering/
â”‚
â”œâ”€â”€ app.py                      # Main Gradio application
â”œâ”€â”€ config.py                   # Configuration and environment management
â”œâ”€â”€ pdf_processor.py            # PDF text extraction and chunking
â”œâ”€â”€ grok_handler.py            # Grok API wrapper
â”œâ”€â”€ rag_manager.py             # LightRAG integration
â”œâ”€â”€ handbook_generator.py      # LongWriter implementation
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Environment variables (create from template)
â”œâ”€â”€ env_template.txt          # Template for environment setup
â”œâ”€â”€ .gitignore                # Git ignore rules
â”‚
â”œâ”€â”€ SETUP.md                  # Detailed setup instructions
â”œâ”€â”€ DEMO_GUIDE.md            # Demo creation guide
â”œâ”€â”€ PROJECT_README.md        # This file
â”œâ”€â”€ test_system.py           # System test script
â”‚
â”œâ”€â”€ uploads/                 # Temporary PDF storage (auto-created)
â”œâ”€â”€ cache/                   # LightRAG cache (auto-created)
â”‚
â””â”€â”€ LongWriter-main/         # Reference implementation (provided)
    â””â”€â”€ agentwrite/
        â”œâ”€â”€ plan.py          # Planning logic reference
        â””â”€â”€ write.py         # Writing logic reference
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Grok API key from [x.ai](https://x.ai)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd SilverAI-Assignment-AI-Engineering

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp env_template.txt .env
# Edit .env and add your GROK_API_KEY

# Run application
python app.py
```

### Access

Open browser to: `http://localhost:7860`

---

## ğŸ“– Usage Guide

### 1. Upload Documents

1. Click **"Upload PDF"** button
2. Select PDF file(s)
3. Wait for processing confirmation
4. See file listed in "Uploaded Files"

### 2. Ask Questions (Q&A Mode)

Type questions about your documents:

```
"What are the main findings?"
"Explain the methodology used"
"Summarize the key concepts"
```

System retrieves relevant context using LightRAG and generates responses using Grok.

### 3. Generate Handbook

Request a comprehensive handbook:

```
"Create a handbook on Machine Learning"
"Generate a comprehensive guide about RAG systems"
"Write a manual on the uploaded research"
```

**System Process:**
1. Detects handbook request
2. Generates detailed outline (~20 sections)
3. Retrieves relevant context for each section
4. Writes each section iteratively (LongWriter technique)
5. Returns 20,000+ word structured document

**Time:** 5-15 minutes depending on complexity

---

## ğŸ§  Technical Implementation

### LongWriter Technique

Based on the research paper in `Documentation/`, the system uses a **plan-then-write** approach:

1. **Planning Phase**
   - Generate comprehensive outline
   - Break topic into 15-25 sections
   - Allocate ~1000 words per section

2. **Writing Phase**
   - Iterate through each section
   - Retrieve relevant context from knowledge graph
   - Generate section with awareness of previous content
   - Maintain consistency and avoid repetition

3. **Assembly Phase**
   - Combine all sections
   - Add table of contents
   - Format with proper headings
   - Validate word count (20,000+ target)

### RAG Implementation

**Document Ingestion:**
```python
PDF â†’ Extract Text â†’ Chunk (1000 words, 200 overlap)
  â†’ Generate Embeddings â†’ Store in LightRAG
```

**Query Processing:**
```python
User Query â†’ Embed Query â†’ Retrieve Top-K Chunks
  â†’ Assemble Context â†’ Send to LLM â†’ Generate Response
```

### Key Modules

#### `pdf_processor.py`
- Extracts text from PDFs using multiple methods
- Intelligent text cleaning
- Smart chunking with overlap
- Metadata extraction

#### `grok_handler.py`
- Wraps Grok API calls
- Implements retry logic with exponential backoff
- Context-aware generation
- Error handling

#### `rag_manager.py`
- Initializes LightRAG
- Manages document storage
- Handles asynchronous operations
- Provides context retrieval

#### `handbook_generator.py`
- Implements LongWriter technique
- Detects handbook requests
- Generates outlines
- Writes sections iteratively
- Manages generation progress

#### `app.py`
- Gradio interface
- Orchestrates all components
- Handles user interactions
- Manages state

---

## ğŸ”§ Configuration

### Environment Variables

Required in `.env`:

```env
# Grok API (Required)
GROK_API_KEY=your_key_here
GROK_API_BASE=https://api.x.ai/v1

# Optional Configuration
EMBEDDING_MODEL=text-embedding-3-small
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_HANDBOOK_LENGTH=20000
```

### Customization

**Adjust chunking:**
```python
pdf_processor = PDFProcessor(chunk_size=1500, chunk_overlap=300)
```

**Change generation temperature:**
```python
grok.generate_response(prompt, temperature=0.5)  # More focused
```

**Modify handbook length:**
```python
handbook_gen.generate_handbook(topic, target_length=30000)
```

---

## ğŸ§ª Testing

### Run System Test

```bash
python test_system.py
```

Tests:
- âœ… Configuration loading
- âœ… PDF processing
- âœ… Grok API connection
- âœ… RAG manager initialization
- âœ… Handbook detection

### Manual Testing

1. **PDF Upload Test:**
   - Upload sample PDF
   - Verify extraction in status message
   - Check "Uploaded Files" list

2. **Q&A Test:**
   - Ask simple question
   - Ask complex question
   - Verify contextual responses

3. **Handbook Test:**
   - Request handbook on specific topic
   - Monitor generation progress
   - Verify 20,000+ word output
   - Check structure and formatting

---

## ğŸ“Š Performance

### Expected Metrics

| Operation | Time | Notes |
|-----------|------|-------|
| PDF Upload | 1-5s | Depends on file size |
| Q&A Response | 2-5s | Single query |
| Handbook Generation | 5-15m | ~20-30 API calls |
| Section Generation | 30-60s | Per section |

### Resource Usage

- **Memory:** ~2-4 GB (LightRAG + embeddings)
- **Storage:** ~100 MB per 100 pages of PDFs
- **API Calls:** ~25-35 per handbook generation

---

## ğŸ› Troubleshooting

### Common Issues

**"Missing required environment variables"**
- Solution: Create `.env` file with `GROK_API_KEY`

**"Error processing PDF"**
- Solution: Ensure PDF is text-based (not scanned image)

**"LightRAG import error"**
- Solution: `pip install lightrag-hku`

**"Torch not found"**
- Solution: `pip install torch` (CPU version is fine)

See `SETUP.md` for detailed troubleshooting.

---

## ğŸ“ Assignment Compliance

### Requirements Met

âœ… **PDF Upload** - Accepts and parses PDF files  
âœ… **Knowledge Graph** - LightRAG stores content  
âœ… **Chat Interface** - Gradio text input/output  
âœ… **Contextual Responses** - RAG retrieval working  
âœ… **Handbook Generation** - 20,000+ words via chat  
âœ… **Proper Structure** - TOC, headings, sections  
âœ… **LongWriter Technique** - Plan-then-write implementation  
âœ… **Grok 4.1 Integration** - Primary LLM  
âœ… **Working Demo** - Full application functional

### Test Case (from README.md)

**Input:**
- Upload 2-3 AI-related PDFs
- Chat: "Create a handbook on Retrieval-Augmented Generation"

**Expected Output:**
- 20,000+ word structured document âœ…
- Table of contents âœ…
- Sections with proper headings âœ…
- Citations from uploaded PDFs âœ…

---

## ğŸ“¦ Deliverables

### Code
- âœ… Complete Python application
- âœ… Modular, well-structured code
- âœ… Configuration management
- âœ… Error handling

### Documentation
- âœ… `SETUP.md` - Installation instructions
- âœ… `DEMO_GUIDE.md` - Demo creation guide
- âœ… `PROJECT_README.md` - This file
- âœ… Inline code comments
- âœ… Test script

### Demo
- Create video or screenshots following `DEMO_GUIDE.md`
- Show: Upload â†’ Q&A â†’ Handbook generation
- Prove: 20,000+ word output

---

## ğŸ”’ Notes

- API keys stored in `.env` (not committed)
- Cache directory excluded from git
- PDF uploads temporary (can be cleared)
- LightRAG stores data locally

---

## ğŸ“§ Submission

**To:** tk.lunartech@gmail.com

**Include:**
1. GitHub repository link (or .zip)
2. SETUP.md instructions
3. Demo video OR screenshots
4. Brief write-up (approach, challenges, solutions)

---

## ğŸ“ Learning Outcomes

This project demonstrates:
- ğŸ”¹ **AI Engineering** - Integrating multiple AI services
- ğŸ”¹ **RAG Systems** - Knowledge graph creation and retrieval
- ğŸ”¹ **LLM Integration** - Grok API usage and prompt engineering
- ğŸ”¹ **Long-form Generation** - LongWriter technique implementation
- ğŸ”¹ **Full-stack Development** - Backend logic + UI
- ğŸ”¹ **Software Engineering** - Modular design, error handling, testing

---

## ğŸ™ Acknowledgments

- **LunarTech** - Assignment and resources
- **LongWriter Research** - Paper and reference implementation
- **LightRAG** - Knowledge graph framework
- **xAI** - Grok API
- **Gradio** - UI framework

---

## ğŸ“„ License

This project is for educational and evaluation purposes as part of the LunarTech AI Engineering assignment.

---

**Built with ğŸ¤– AI assistance (as encouraged by the assignment guidelines)**

_For questions or issues, refer to SETUP.md or contact through submission email._
